import pandas as pd
import numpy as np

data= pd.read_csv("c:\\loan prediction.csv")

data['TotalIncome']=data['ApplicantIncome']+ data['CoapplicantIncome']

data1 = data[['TotalIncome','LoanAmount']]
data1.isnull().sum()
med1 = int(data1['LoanAmount'].median())
data1['LoanAmount'].fillna(med1,inplace = True)

x =data1.values
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X =sc.fit_transform(x)

#Using the dendogram to find the optimal number of cluster
import matplotlib.pyplot as plt
import scipy.cluster.hierarchy as sch
dendrogram = sch.dendrogram(sch.linkage(X,method='ward'))
plt.title('Dendrogram')
plt.title('Customer')
plt.ylabel('Euclidean Distance')

#fitting the Hierarchical clustering to the dataset
from sklearn.cluster import AgglomerativeClustering
hc = AgglomerativeClustering(n_clusters=5,affinity="euclidean",linkage='ward')
y_hc = hc.fit_predict(X)

#visualizing the cluster
plt.scatter(X[y_hc ==0,0],X[y_hc== 0, 1],s =100,c = 'Green')
plt.scatter(X[y_hc ==1,0],X[y_hc== 1, 1],s =100,c = 'Cyan')
plt.scatter(X[y_hc ==2,0],X[y_hc== 2, 1],s =100,c = 'Red')
plt.scatter(X[y_hc ==3,0],X[y_hc== 3, 1],s =100,c = 'Blue')
plt.scatter(X[y_hc ==4,0],X[y_hc== 4, 1],s =100,c = 'Orange')
plt.title('Clusters of Customers')
plt.xlabel('Annual Income')
plt.ylabel('Loan Amount')
plt.show()
